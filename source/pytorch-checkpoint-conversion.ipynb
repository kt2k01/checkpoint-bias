{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1DEd1q7oZZmYb2VkkFyb2jtxZdQsGh6YC","authorship_tag":"ABX9TyPNRZCsmcvrjt0XF1Wh+df4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2R6k4wq1qAqe","executionInfo":{"status":"ok","timestamp":1667608572451,"user_tz":300,"elapsed":4664,"user":{"displayName":"Kenan Tang","userId":"17854402159298566409"}},"outputId":"e7536e32-31f6-4470-fd38-2df119eda649"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.24.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","source":["# get all steps\n","\n","from glob import glob\n","\n","steps = []\n","\n","# extract number from the file names\n","for dir in glob('/content/drive/MyDrive/bert-checkpoints/seed_0/*'):\n","    steps.append(int(dir.split('_')[-1]))\n","\n","# sort in ascending order\n","steps = sorted(steps)\n","\n","# should be 28+1=29\n","print(len(steps))\n","\n","# save the steps to a local file\n","with open('/content/drive/MyDrive/bert-checkpoints/steps.txt', 'w') as f:\n","    for step in steps:\n","        f.write(str(step)+'\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PVNzQ8VSEEbI","executionInfo":{"status":"ok","timestamp":1667608578453,"user_tz":300,"elapsed":215,"user":{"displayName":"Kenan Tang","userId":"17854402159298566409"}},"outputId":"43f8934b-dd1e-451a-d626-f7ac47fd6b3c"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["29\n"]}]},{"cell_type":"code","source":["steps[16:]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oVzKRwrvN6lG","executionInfo":{"status":"ok","timestamp":1667608599226,"user_tz":300,"elapsed":4,"user":{"displayName":"Kenan Tang","userId":"17854402159298566409"}},"outputId":"62413e2c-ed53-4c4d-95ed-53880655ad78"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[800000,\n"," 900000,\n"," 1000000,\n"," 1100000,\n"," 1200000,\n"," 1300000,\n"," 1400000,\n"," 1500000,\n"," 1600000,\n"," 1700000,\n"," 1800000,\n"," 1900000,\n"," 2000000]"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["# the base directory\n","base_dir = '/content/drive/MyDrive/bert-checkpoints'\n","cfg_dir = '/content/drive/MyDrive/bert-checkpoints/bert_config.json'\n","\n","# loop over 5 seeds\n","# for seed in [0, 1, 2, 3, 4]:\n","for seed in [4]:\n","\n","    # create parent directory for each seed\n","    !cd $base_dir/pytorch_checkpoints && mkdir seed_$seed\n","\n","    # loop over 29 steps\n","    # for step in steps:\n","\n","    # first half\n","    # for step in steps[:15]:\n","\n","    # second half\n","    for step in steps[15:]:\n","\n","        # the directory of the tf model\n","        tf_dir = f'{base_dir}/seed_{seed}/step_{step}'\n","\n","        # the output directory of the pytorch model\n","        dump_dir = f'{base_dir}/pytorch_checkpoints/seed_{seed}/step_{step}'\n","\n","        # make new directory for each checkpoint\n","        !cd $base_dir/pytorch_checkpoints/seed_$seed && mkdir step_$step\n","\n","        # copy config file to the dump directory\n","        !cp $cfg_dir $dump_dir/config.json\n","\n","        # convert\n","        !transformers-cli convert --model_type bert \\\n","          --tf_checkpoint $tf_dir/bert.ckpt \\\n","          --config $dump_dir/config.json \\\n","          --pytorch_dump_output $dump_dir/pytorch_model.bin\n","\n","        # for testing purpose\n","        # break\n","\n","    # for testing purpose\n","    # break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CRtFQ9VyE2tg","executionInfo":{"status":"ok","timestamp":1667617600959,"user_tz":300,"elapsed":924554,"user":{"displayName":"Kenan Tang","userId":"17854402159298566409"}},"outputId":"6d68d179-365c-4d8a-b8e7-9da5e6c4333c"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","Initialize PyTorch weight ['bert', 'embeddings', 'position_embeddings']\n","Initialize PyTorch weight ['bert', 'embeddings', 'token_type_embeddings']\n","Initialize PyTorch weight ['bert', 'embeddings', 'word_embeddings']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'pooler', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'pooler', 'dense', 'kernel']\n","Initialize PyTorch weight ['cls', 'predictions', 'output_bias']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'dense', 'bias']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'dense', 'kernel']\n","Initialize PyTorch weight ['cls', 'seq_relationship', 'output_bias']\n","Initialize PyTorch weight ['cls', 'seq_relationship', 'output_weights']\n","Save PyTorch model to /content/drive/MyDrive/bert-checkpoints/pytorch_checkpoints/seed_4/step_900000/pytorch_model.bin\n","Building PyTorch model from configuration: BertConfig {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","Converting TensorFlow checkpoint from /content/drive/MyDrive/bert-checkpoints/seed_4/step_1000000/bert.ckpt\n","Loading TF weight bert/embeddings/LayerNorm/beta with shape [768]\n","Loading TF weight bert/embeddings/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/embeddings/position_embeddings with shape [512, 768]\n","Loading TF weight bert/embeddings/token_type_embeddings with shape [2, 768]\n","Loading TF weight bert/embeddings/word_embeddings with shape [30522, 768]\n","2022-11-05 02:54:44.354810: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 93763584 exceeds 10% of free system memory.\n","Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_0/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_0/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_0/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_0/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_1/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_1/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_1/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_1/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_10/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_10/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_10/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_10/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_11/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_11/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_11/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_11/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_2/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_2/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_2/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_2/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_3/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_3/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_3/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_3/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_4/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_4/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_4/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_4/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_5/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_5/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_5/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_5/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_6/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_6/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_6/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_6/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_7/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_7/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_7/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_7/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_8/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_8/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_8/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_8/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_9/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_9/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_9/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_9/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/pooler/dense/bias with shape [768]\n","Loading TF weight bert/pooler/dense/kernel with shape [768, 768]\n","Loading TF weight cls/predictions/output_bias with shape [30522]\n","Loading TF weight cls/predictions/transform/LayerNorm/beta with shape [768]\n","Loading TF weight cls/predictions/transform/LayerNorm/gamma with shape [768]\n","Loading TF weight cls/predictions/transform/dense/bias with shape [768]\n","Loading TF weight cls/predictions/transform/dense/kernel with shape [768, 768]\n","Loading TF weight cls/seq_relationship/output_bias with shape [2]\n","Loading TF weight cls/seq_relationship/output_weights with shape [2, 768]\n","Initialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'embeddings', 'position_embeddings']\n","Initialize PyTorch weight ['bert', 'embeddings', 'token_type_embeddings']\n","Initialize PyTorch weight ['bert', 'embeddings', 'word_embeddings']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'pooler', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'pooler', 'dense', 'kernel']\n","Initialize PyTorch weight ['cls', 'predictions', 'output_bias']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'dense', 'bias']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'dense', 'kernel']\n","Initialize PyTorch weight ['cls', 'seq_relationship', 'output_bias']\n","Initialize PyTorch weight ['cls', 'seq_relationship', 'output_weights']\n","Save PyTorch model to /content/drive/MyDrive/bert-checkpoints/pytorch_checkpoints/seed_4/step_1000000/pytorch_model.bin\n","Building PyTorch model from configuration: BertConfig {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","Converting TensorFlow checkpoint from /content/drive/MyDrive/bert-checkpoints/seed_4/step_1100000/bert.ckpt\n","Loading TF weight bert/embeddings/LayerNorm/beta with shape [768]\n","Loading TF weight bert/embeddings/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/embeddings/position_embeddings with shape [512, 768]\n","Loading TF weight bert/embeddings/token_type_embeddings with shape [2, 768]\n","Loading TF weight bert/embeddings/word_embeddings with shape [30522, 768]\n","2022-11-05 02:55:51.903245: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 93763584 exceeds 10% of free system memory.\n","Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_0/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_0/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_0/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_0/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_1/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_1/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_1/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_1/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_10/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_10/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_10/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_10/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_11/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_11/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_11/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_11/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_2/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_2/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_2/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_2/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_3/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_3/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_3/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_3/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_4/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_4/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_4/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_4/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_5/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_5/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_5/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_5/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_6/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_6/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_6/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_6/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_7/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_7/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_7/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_7/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_8/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_8/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_8/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_8/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_9/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_9/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_9/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_9/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/pooler/dense/bias with shape [768]\n","Loading TF weight bert/pooler/dense/kernel with shape [768, 768]\n","Loading TF weight cls/predictions/output_bias with shape [30522]\n","Loading TF weight cls/predictions/transform/LayerNorm/beta with shape [768]\n","Loading TF weight cls/predictions/transform/LayerNorm/gamma with shape [768]\n","Loading TF weight cls/predictions/transform/dense/bias with shape [768]\n","Loading TF weight cls/predictions/transform/dense/kernel with shape [768, 768]\n","Loading TF weight cls/seq_relationship/output_bias with shape [2]\n","Loading TF weight cls/seq_relationship/output_weights with shape [2, 768]\n","Initialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'embeddings', 'position_embeddings']\n","Initialize PyTorch weight ['bert', 'embeddings', 'token_type_embeddings']\n","Initialize PyTorch weight ['bert', 'embeddings', 'word_embeddings']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'pooler', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'pooler', 'dense', 'kernel']\n","Initialize PyTorch weight ['cls', 'predictions', 'output_bias']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'dense', 'bias']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'dense', 'kernel']\n","Initialize PyTorch weight ['cls', 'seq_relationship', 'output_bias']\n","Initialize PyTorch weight ['cls', 'seq_relationship', 'output_weights']\n","Save PyTorch model to /content/drive/MyDrive/bert-checkpoints/pytorch_checkpoints/seed_4/step_1100000/pytorch_model.bin\n","Building PyTorch model from configuration: BertConfig {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","Converting TensorFlow checkpoint from /content/drive/MyDrive/bert-checkpoints/seed_4/step_1200000/bert.ckpt\n","Loading TF weight bert/embeddings/LayerNorm/beta with shape [768]\n","Loading TF weight bert/embeddings/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/embeddings/position_embeddings with shape [512, 768]\n","Loading TF weight bert/embeddings/token_type_embeddings with shape [2, 768]\n","Loading TF weight bert/embeddings/word_embeddings with shape [30522, 768]\n","2022-11-05 02:56:57.119442: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 93763584 exceeds 10% of free system memory.\n","Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_0/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_0/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_0/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_0/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_1/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_1/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_1/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_1/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_10/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_10/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_10/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_10/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_11/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_11/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_11/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_11/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_2/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_2/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_2/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_2/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_3/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_3/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_3/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_3/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_4/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_4/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_4/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_4/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_5/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_5/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_5/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_5/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_6/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_6/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_6/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_6/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_7/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_7/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_7/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_7/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_8/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_8/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_8/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_8/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_9/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_9/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_9/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_9/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/pooler/dense/bias with shape [768]\n","Loading TF weight bert/pooler/dense/kernel with shape [768, 768]\n","Loading TF weight cls/predictions/output_bias with shape [30522]\n","Loading TF weight cls/predictions/transform/LayerNorm/beta with shape [768]\n","Loading TF weight cls/predictions/transform/LayerNorm/gamma with shape [768]\n","Loading TF weight cls/predictions/transform/dense/bias with shape [768]\n","Loading TF weight cls/predictions/transform/dense/kernel with shape [768, 768]\n","Loading TF weight cls/seq_relationship/output_bias with shape [2]\n","Loading TF weight cls/seq_relationship/output_weights with shape [2, 768]\n","Initialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'embeddings', 'position_embeddings']\n","Initialize PyTorch weight ['bert', 'embeddings', 'token_type_embeddings']\n","Initialize PyTorch weight ['bert', 'embeddings', 'word_embeddings']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'pooler', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'pooler', 'dense', 'kernel']\n","Initialize PyTorch weight ['cls', 'predictions', 'output_bias']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'dense', 'bias']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'dense', 'kernel']\n","Initialize PyTorch weight ['cls', 'seq_relationship', 'output_bias']\n","Initialize PyTorch weight ['cls', 'seq_relationship', 'output_weights']\n","Save PyTorch model to /content/drive/MyDrive/bert-checkpoints/pytorch_checkpoints/seed_4/step_1200000/pytorch_model.bin\n","Building PyTorch model from configuration: BertConfig {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","Converting TensorFlow checkpoint from /content/drive/MyDrive/bert-checkpoints/seed_4/step_1300000/bert.ckpt\n","Loading TF weight bert/embeddings/LayerNorm/beta with shape [768]\n","Loading TF weight bert/embeddings/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/embeddings/position_embeddings with shape [512, 768]\n","Loading TF weight bert/embeddings/token_type_embeddings with shape [2, 768]\n","Loading TF weight bert/embeddings/word_embeddings with shape [30522, 768]\n","2022-11-05 02:58:01.008073: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 93763584 exceeds 10% of free system memory.\n","Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_0/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_0/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_0/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_0/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_1/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_1/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_1/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_1/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_10/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_10/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_10/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_10/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_11/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_11/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_11/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_11/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_2/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_2/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_2/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_2/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_3/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_3/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_3/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_3/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_4/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_4/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_4/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_4/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_5/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_5/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_5/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_5/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_6/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_6/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_6/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_6/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_7/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_7/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_7/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_7/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_8/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_8/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_8/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_8/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_9/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_9/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_9/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_9/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/pooler/dense/bias with shape [768]\n","Loading TF weight bert/pooler/dense/kernel with shape [768, 768]\n","Loading TF weight cls/predictions/output_bias with shape [30522]\n","Loading TF weight cls/predictions/transform/LayerNorm/beta with shape [768]\n","Loading TF weight cls/predictions/transform/LayerNorm/gamma with shape [768]\n","Loading TF weight cls/predictions/transform/dense/bias with shape [768]\n","Loading TF weight cls/predictions/transform/dense/kernel with shape [768, 768]\n","Loading TF weight cls/seq_relationship/output_bias with shape [2]\n","Loading TF weight cls/seq_relationship/output_weights with shape [2, 768]\n","Initialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'embeddings', 'position_embeddings']\n","Initialize PyTorch weight ['bert', 'embeddings', 'token_type_embeddings']\n","Initialize PyTorch weight ['bert', 'embeddings', 'word_embeddings']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'pooler', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'pooler', 'dense', 'kernel']\n","Initialize PyTorch weight ['cls', 'predictions', 'output_bias']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'dense', 'bias']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'dense', 'kernel']\n","Initialize PyTorch weight ['cls', 'seq_relationship', 'output_bias']\n","Initialize PyTorch weight ['cls', 'seq_relationship', 'output_weights']\n","Save PyTorch model to /content/drive/MyDrive/bert-checkpoints/pytorch_checkpoints/seed_4/step_1300000/pytorch_model.bin\n","Building PyTorch model from configuration: BertConfig {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","Converting TensorFlow checkpoint from /content/drive/MyDrive/bert-checkpoints/seed_4/step_1400000/bert.ckpt\n","Loading TF weight bert/embeddings/LayerNorm/beta with shape [768]\n","Loading TF weight bert/embeddings/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/embeddings/position_embeddings with shape [512, 768]\n","Loading TF weight bert/embeddings/token_type_embeddings with shape [2, 768]\n","Loading TF weight bert/embeddings/word_embeddings with shape [30522, 768]\n","Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_0/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_0/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_0/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_0/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_1/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_1/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_1/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_1/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_10/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_10/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_10/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_10/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_11/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_11/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_11/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_11/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_2/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_2/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_2/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_2/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_3/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_3/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_3/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_3/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_4/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_4/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_4/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_4/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_5/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_5/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_5/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_5/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_6/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_6/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_6/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_6/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_7/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_7/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_7/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_7/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_8/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_8/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_8/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_8/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_9/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_9/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_9/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_9/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/pooler/dense/bias with shape [768]\n","Loading TF weight bert/pooler/dense/kernel with shape [768, 768]\n","Loading TF weight cls/predictions/output_bias with shape [30522]\n","Loading TF weight cls/predictions/transform/LayerNorm/beta with shape [768]\n","Loading TF weight cls/predictions/transform/LayerNorm/gamma with shape [768]\n","Loading TF weight cls/predictions/transform/dense/bias with shape [768]\n","Loading TF weight cls/predictions/transform/dense/kernel with shape [768, 768]\n","Loading TF weight cls/seq_relationship/output_bias with shape [2]\n","Loading TF weight cls/seq_relationship/output_weights with shape [2, 768]\n","Initialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'embeddings', 'position_embeddings']\n","Initialize PyTorch weight ['bert', 'embeddings', 'token_type_embeddings']\n","Initialize PyTorch weight ['bert', 'embeddings', 'word_embeddings']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'pooler', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'pooler', 'dense', 'kernel']\n","Initialize PyTorch weight ['cls', 'predictions', 'output_bias']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'dense', 'bias']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'dense', 'kernel']\n","Initialize PyTorch weight ['cls', 'seq_relationship', 'output_bias']\n","Initialize PyTorch weight ['cls', 'seq_relationship', 'output_weights']\n","Save PyTorch model to /content/drive/MyDrive/bert-checkpoints/pytorch_checkpoints/seed_4/step_1400000/pytorch_model.bin\n","Building PyTorch model from configuration: BertConfig {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","Converting TensorFlow checkpoint from /content/drive/MyDrive/bert-checkpoints/seed_4/step_1500000/bert.ckpt\n","Loading TF weight bert/embeddings/LayerNorm/beta with shape [768]\n","Loading TF weight bert/embeddings/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/embeddings/position_embeddings with shape [512, 768]\n","Loading TF weight bert/embeddings/token_type_embeddings with shape [2, 768]\n","Loading TF weight bert/embeddings/word_embeddings with shape [30522, 768]\n","2022-11-05 03:00:06.410673: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 93763584 exceeds 10% of free system memory.\n","Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_0/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_0/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_0/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_0/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_1/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_1/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_1/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_1/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_10/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_10/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_10/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_10/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_11/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_11/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_11/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_11/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_2/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_2/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_2/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_2/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_3/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_3/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_3/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_3/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_4/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_4/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_4/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_4/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_5/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_5/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_5/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_5/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_6/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_6/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_6/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_6/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_7/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_7/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_7/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_7/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_8/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_8/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_8/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_8/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_9/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_9/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_9/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_9/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/pooler/dense/bias with shape [768]\n","Loading TF weight bert/pooler/dense/kernel with shape [768, 768]\n","Loading TF weight cls/predictions/output_bias with shape [30522]\n","Loading TF weight cls/predictions/transform/LayerNorm/beta with shape [768]\n","Loading TF weight cls/predictions/transform/LayerNorm/gamma with shape [768]\n","Loading TF weight cls/predictions/transform/dense/bias with shape [768]\n","Loading TF weight cls/predictions/transform/dense/kernel with shape [768, 768]\n","Loading TF weight cls/seq_relationship/output_bias with shape [2]\n","Loading TF weight cls/seq_relationship/output_weights with shape [2, 768]\n","Initialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'embeddings', 'position_embeddings']\n","Initialize PyTorch weight ['bert', 'embeddings', 'token_type_embeddings']\n","Initialize PyTorch weight ['bert', 'embeddings', 'word_embeddings']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'pooler', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'pooler', 'dense', 'kernel']\n","Initialize PyTorch weight ['cls', 'predictions', 'output_bias']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'dense', 'bias']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'dense', 'kernel']\n","Initialize PyTorch weight ['cls', 'seq_relationship', 'output_bias']\n","Initialize PyTorch weight ['cls', 'seq_relationship', 'output_weights']\n","Save PyTorch model to /content/drive/MyDrive/bert-checkpoints/pytorch_checkpoints/seed_4/step_1500000/pytorch_model.bin\n","Building PyTorch model from configuration: BertConfig {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","Converting TensorFlow checkpoint from /content/drive/MyDrive/bert-checkpoints/seed_4/step_1600000/bert.ckpt\n","Loading TF weight bert/embeddings/LayerNorm/beta with shape [768]\n","Loading TF weight bert/embeddings/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/embeddings/position_embeddings with shape [512, 768]\n","Loading TF weight bert/embeddings/token_type_embeddings with shape [2, 768]\n","Loading TF weight bert/embeddings/word_embeddings with shape [30522, 768]\n","2022-11-05 03:01:13.228315: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 93763584 exceeds 10% of free system memory.\n","Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_0/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_0/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_0/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_0/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_1/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_1/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_1/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_1/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_10/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_10/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_10/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_10/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_11/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_11/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_11/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_11/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_2/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_2/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_2/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_2/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_3/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_3/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_3/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_3/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_4/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_4/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_4/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_4/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_5/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_5/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_5/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_5/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_6/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_6/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_6/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_6/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_7/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_7/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_7/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_7/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_8/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_8/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_8/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_8/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_9/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_9/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_9/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_9/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/pooler/dense/bias with shape [768]\n","Loading TF weight bert/pooler/dense/kernel with shape [768, 768]\n","Loading TF weight cls/predictions/output_bias with shape [30522]\n","Loading TF weight cls/predictions/transform/LayerNorm/beta with shape [768]\n","Loading TF weight cls/predictions/transform/LayerNorm/gamma with shape [768]\n","Loading TF weight cls/predictions/transform/dense/bias with shape [768]\n","Loading TF weight cls/predictions/transform/dense/kernel with shape [768, 768]\n","Loading TF weight cls/seq_relationship/output_bias with shape [2]\n","Loading TF weight cls/seq_relationship/output_weights with shape [2, 768]\n","Initialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'embeddings', 'position_embeddings']\n","Initialize PyTorch weight ['bert', 'embeddings', 'token_type_embeddings']\n","Initialize PyTorch weight ['bert', 'embeddings', 'word_embeddings']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'pooler', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'pooler', 'dense', 'kernel']\n","Initialize PyTorch weight ['cls', 'predictions', 'output_bias']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'dense', 'bias']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'dense', 'kernel']\n","Initialize PyTorch weight ['cls', 'seq_relationship', 'output_bias']\n","Initialize PyTorch weight ['cls', 'seq_relationship', 'output_weights']\n","Save PyTorch model to /content/drive/MyDrive/bert-checkpoints/pytorch_checkpoints/seed_4/step_1600000/pytorch_model.bin\n","Building PyTorch model from configuration: BertConfig {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","Converting TensorFlow checkpoint from /content/drive/MyDrive/bert-checkpoints/seed_4/step_1700000/bert.ckpt\n","Loading TF weight bert/embeddings/LayerNorm/beta with shape [768]\n","Loading TF weight bert/embeddings/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/embeddings/position_embeddings with shape [512, 768]\n","Loading TF weight bert/embeddings/token_type_embeddings with shape [2, 768]\n","Loading TF weight bert/embeddings/word_embeddings with shape [30522, 768]\n","2022-11-05 03:02:17.461321: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 93763584 exceeds 10% of free system memory.\n","Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_0/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_0/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_0/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_0/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_1/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_1/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_1/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_1/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_10/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_10/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_10/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_10/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_11/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_11/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_11/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_11/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_2/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_2/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_2/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_2/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_3/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_3/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_3/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_3/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_4/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_4/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_4/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_4/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_5/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_5/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_5/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_5/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_6/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_6/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_6/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_6/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_7/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_7/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_7/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_7/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_8/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_8/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_8/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_8/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_9/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_9/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_9/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_9/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/pooler/dense/bias with shape [768]\n","Loading TF weight bert/pooler/dense/kernel with shape [768, 768]\n","Loading TF weight cls/predictions/output_bias with shape [30522]\n","Loading TF weight cls/predictions/transform/LayerNorm/beta with shape [768]\n","Loading TF weight cls/predictions/transform/LayerNorm/gamma with shape [768]\n","Loading TF weight cls/predictions/transform/dense/bias with shape [768]\n","Loading TF weight cls/predictions/transform/dense/kernel with shape [768, 768]\n","Loading TF weight cls/seq_relationship/output_bias with shape [2]\n","Loading TF weight cls/seq_relationship/output_weights with shape [2, 768]\n","Initialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'embeddings', 'position_embeddings']\n","Initialize PyTorch weight ['bert', 'embeddings', 'token_type_embeddings']\n","Initialize PyTorch weight ['bert', 'embeddings', 'word_embeddings']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'pooler', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'pooler', 'dense', 'kernel']\n","Initialize PyTorch weight ['cls', 'predictions', 'output_bias']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'dense', 'bias']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'dense', 'kernel']\n","Initialize PyTorch weight ['cls', 'seq_relationship', 'output_bias']\n","Initialize PyTorch weight ['cls', 'seq_relationship', 'output_weights']\n","Save PyTorch model to /content/drive/MyDrive/bert-checkpoints/pytorch_checkpoints/seed_4/step_1700000/pytorch_model.bin\n","Building PyTorch model from configuration: BertConfig {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","Converting TensorFlow checkpoint from /content/drive/MyDrive/bert-checkpoints/seed_4/step_1800000/bert.ckpt\n","Loading TF weight bert/embeddings/LayerNorm/beta with shape [768]\n","Loading TF weight bert/embeddings/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/embeddings/position_embeddings with shape [512, 768]\n","Loading TF weight bert/embeddings/token_type_embeddings with shape [2, 768]\n","Loading TF weight bert/embeddings/word_embeddings with shape [30522, 768]\n","2022-11-05 03:03:25.242402: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 93763584 exceeds 10% of free system memory.\n","Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_0/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_0/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_0/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_0/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_1/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_1/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_1/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_1/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_10/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_10/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_10/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_10/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_11/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_11/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_11/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_11/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_2/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_2/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_2/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_2/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_3/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_3/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_3/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_3/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_4/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_4/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_4/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_4/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_5/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_5/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_5/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_5/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_6/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_6/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_6/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_6/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_7/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_7/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_7/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_7/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_8/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_8/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_8/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_8/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_9/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_9/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_9/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_9/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/pooler/dense/bias with shape [768]\n","Loading TF weight bert/pooler/dense/kernel with shape [768, 768]\n","Loading TF weight cls/predictions/output_bias with shape [30522]\n","Loading TF weight cls/predictions/transform/LayerNorm/beta with shape [768]\n","Loading TF weight cls/predictions/transform/LayerNorm/gamma with shape [768]\n","Loading TF weight cls/predictions/transform/dense/bias with shape [768]\n","Loading TF weight cls/predictions/transform/dense/kernel with shape [768, 768]\n","Loading TF weight cls/seq_relationship/output_bias with shape [2]\n","Loading TF weight cls/seq_relationship/output_weights with shape [2, 768]\n","Initialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'embeddings', 'position_embeddings']\n","Initialize PyTorch weight ['bert', 'embeddings', 'token_type_embeddings']\n","Initialize PyTorch weight ['bert', 'embeddings', 'word_embeddings']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'pooler', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'pooler', 'dense', 'kernel']\n","Initialize PyTorch weight ['cls', 'predictions', 'output_bias']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'dense', 'bias']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'dense', 'kernel']\n","Initialize PyTorch weight ['cls', 'seq_relationship', 'output_bias']\n","Initialize PyTorch weight ['cls', 'seq_relationship', 'output_weights']\n","Save PyTorch model to /content/drive/MyDrive/bert-checkpoints/pytorch_checkpoints/seed_4/step_1800000/pytorch_model.bin\n","Building PyTorch model from configuration: BertConfig {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","Converting TensorFlow checkpoint from /content/drive/MyDrive/bert-checkpoints/seed_4/step_1900000/bert.ckpt\n","Loading TF weight bert/embeddings/LayerNorm/beta with shape [768]\n","Loading TF weight bert/embeddings/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/embeddings/position_embeddings with shape [512, 768]\n","Loading TF weight bert/embeddings/token_type_embeddings with shape [2, 768]\n","Loading TF weight bert/embeddings/word_embeddings with shape [30522, 768]\n","2022-11-05 03:04:33.907806: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 93763584 exceeds 10% of free system memory.\n","Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_0/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_0/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_0/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_0/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_1/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_1/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_1/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_1/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_10/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_10/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_10/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_10/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_11/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_11/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_11/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_11/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_2/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_2/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_2/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_2/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_3/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_3/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_3/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_3/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_4/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_4/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_4/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_4/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_5/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_5/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_5/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_5/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_6/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_6/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_6/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_6/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_7/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_7/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_7/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_7/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_8/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_8/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_8/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_8/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_9/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_9/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_9/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_9/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/pooler/dense/bias with shape [768]\n","Loading TF weight bert/pooler/dense/kernel with shape [768, 768]\n","Loading TF weight cls/predictions/output_bias with shape [30522]\n","Loading TF weight cls/predictions/transform/LayerNorm/beta with shape [768]\n","Loading TF weight cls/predictions/transform/LayerNorm/gamma with shape [768]\n","Loading TF weight cls/predictions/transform/dense/bias with shape [768]\n","Loading TF weight cls/predictions/transform/dense/kernel with shape [768, 768]\n","Loading TF weight cls/seq_relationship/output_bias with shape [2]\n","Loading TF weight cls/seq_relationship/output_weights with shape [2, 768]\n","Initialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'embeddings', 'position_embeddings']\n","Initialize PyTorch weight ['bert', 'embeddings', 'token_type_embeddings']\n","Initialize PyTorch weight ['bert', 'embeddings', 'word_embeddings']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'pooler', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'pooler', 'dense', 'kernel']\n","Initialize PyTorch weight ['cls', 'predictions', 'output_bias']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'dense', 'bias']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'dense', 'kernel']\n","Initialize PyTorch weight ['cls', 'seq_relationship', 'output_bias']\n","Initialize PyTorch weight ['cls', 'seq_relationship', 'output_weights']\n","Save PyTorch model to /content/drive/MyDrive/bert-checkpoints/pytorch_checkpoints/seed_4/step_1900000/pytorch_model.bin\n","Building PyTorch model from configuration: BertConfig {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","Converting TensorFlow checkpoint from /content/drive/MyDrive/bert-checkpoints/seed_4/step_2000000/bert.ckpt\n","Loading TF weight bert/embeddings/LayerNorm/beta with shape [768]\n","Loading TF weight bert/embeddings/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/embeddings/position_embeddings with shape [512, 768]\n","Loading TF weight bert/embeddings/token_type_embeddings with shape [2, 768]\n","Loading TF weight bert/embeddings/word_embeddings with shape [30522, 768]\n","2022-11-05 03:05:40.083062: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 93763584 exceeds 10% of free system memory.\n","Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_0/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_0/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_0/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_0/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_1/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_1/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_1/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_1/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_10/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_10/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_10/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_10/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_11/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_11/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_11/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_11/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_2/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_2/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_2/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_2/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_3/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_3/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_3/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_3/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_4/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_4/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_4/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_4/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_5/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_5/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_5/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_5/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_6/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_6/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_6/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_6/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_7/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_7/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_7/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_7/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_8/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_8/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_8/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_8/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_9/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_9/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_9/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_9/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/pooler/dense/bias with shape [768]\n","Loading TF weight bert/pooler/dense/kernel with shape [768, 768]\n","Loading TF weight cls/predictions/output_bias with shape [30522]\n","Loading TF weight cls/predictions/transform/LayerNorm/beta with shape [768]\n","Loading TF weight cls/predictions/transform/LayerNorm/gamma with shape [768]\n","Loading TF weight cls/predictions/transform/dense/bias with shape [768]\n","Loading TF weight cls/predictions/transform/dense/kernel with shape [768, 768]\n","Loading TF weight cls/seq_relationship/output_bias with shape [2]\n","Loading TF weight cls/seq_relationship/output_weights with shape [2, 768]\n","Initialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'embeddings', 'position_embeddings']\n","Initialize PyTorch weight ['bert', 'embeddings', 'token_type_embeddings']\n","Initialize PyTorch weight ['bert', 'embeddings', 'word_embeddings']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'pooler', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'pooler', 'dense', 'kernel']\n","Initialize PyTorch weight ['cls', 'predictions', 'output_bias']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'dense', 'bias']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'dense', 'kernel']\n","Initialize PyTorch weight ['cls', 'seq_relationship', 'output_bias']\n","Initialize PyTorch weight ['cls', 'seq_relationship', 'output_weights']\n","Save PyTorch model to /content/drive/MyDrive/bert-checkpoints/pytorch_checkpoints/seed_4/step_2000000/pytorch_model.bin\n"]}]},{"cell_type":"code","source":["# base_dir = '/content/drive/MyDrive/bert-checkpoints/seed_0/step_2000000'\n","# conf_dir = '/content/drive/MyDrive/bert-checkpoints'\n","# dump_dir = '/content/drive/MyDrive/bert-checkpoints/pytorch_checkpoints'\n","\n","# /content/drive/MyDrive/bert-checkpoints/seed_0/step_0/bert.ckpt.data-00000-of-00001\n","\n","# !transformers-cli convert --model_type bert \\\n","#    --tf_checkpoint $base_dir/bert.ckpt \\\n","#    --config $conf_dir/bert_config.json \\\n","#    --pytorch_dump_output $dump_dir/pytorch_model.bin"],"metadata":{"id":"fJRk4CoOqMIF","executionInfo":{"status":"ok","timestamp":1667606986298,"user_tz":300,"elapsed":234,"user":{"displayName":"Kenan Tang","userId":"17854402159298566409"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["from transformers import pipeline\n","from transformers import AutoModelForMaskedLM, BertTokenizerFast"],"metadata":{"id":"vkklEmEuqunr","executionInfo":{"status":"ok","timestamp":1667605130819,"user_tz":300,"elapsed":210,"user":{"displayName":"Kenan Tang","userId":"17854402159298566409"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# test if model can be loaded\n","\n","model = AutoModelForMaskedLM.from_pretrained(f'/content/drive/MyDrive/bert-checkpoints/pytorch_checkpoints/seed_0/step_0')\n","tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased') # see paper for reference\n","\n","unmasker = pipeline('fill-mask', model=model, tokenizer=tokenizer)\n","\n","# different mask token from RoBERTa\n","prior_templates = [\n","    '[MASK] is a [MASK].',\n","    '[MASK] is an [MASK].',\n","    '[MASK] works as a [MASK].',\n","    '[MASK] works as an [MASK].'\n","]\n","\n","templates = ['[MASK] is a doctor.']\n","\n","# use lower case instead\n","tokens = ['he', 'she']\n","\n","# preview results, use fewer templates\n","unmasker(templates, targets=tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MumD_rIsAssz","executionInfo":{"status":"ok","timestamp":1667606992771,"user_tz":300,"elapsed":2477,"user":{"displayName":"Kenan Tang","userId":"17854402159298566409"}},"outputId":"255b400f-3bb2-4cfa-e223-def555fd070f"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at /content/drive/MyDrive/bert-checkpoints/pytorch_checkpoints/seed_0/step_0 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"execute_result","data":{"text/plain":["[{'score': 5.237394725554623e-05,\n","  'token': 2016,\n","  'token_str': 'she',\n","  'sequence': 'she is a doctor.'},\n"," {'score': 1.906941906781867e-05,\n","  'token': 2002,\n","  'token_str': 'he',\n","  'sequence': 'he is a doctor.'}]"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":[],"metadata":{"id":"Cu9y3HKvBJm8"},"execution_count":null,"outputs":[]}]}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1I3P0hB2c1vB_h6-wDSY06qz2FlW0WJtl","authorship_tag":"ABX9TyOMvtaeSQIvnF2/+BMtqvoP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"87f5061bfcad4f6f8614cc3be5e31586":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e5058439e7f14424bab7bc0e176d612e","IPY_MODEL_9bd72aabc6a249cfb46bc7754e81a586","IPY_MODEL_115a43637959470ea2cebd13810aec50"],"layout":"IPY_MODEL_c7d171e1abce4046a72ea64a997703d1"}},"e5058439e7f14424bab7bc0e176d612e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c3aa636515d34ba08aacaa267770f937","placeholder":"​","style":"IPY_MODEL_d556cd297f224586b1c7feee594ed475","value":"Downloading: 100%"}},"9bd72aabc6a249cfb46bc7754e81a586":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c2297780d944f539fea4fdc9bb96039","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_651acd0fa5074cf1ba0be38d459a5362","value":570}},"115a43637959470ea2cebd13810aec50":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd5f8e39b53e432da6e99df05c931c9d","placeholder":"​","style":"IPY_MODEL_75f852f095b64a2f92f5054aec9a8c21","value":" 570/570 [00:00&lt;00:00, 8.87kB/s]"}},"c7d171e1abce4046a72ea64a997703d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3aa636515d34ba08aacaa267770f937":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d556cd297f224586b1c7feee594ed475":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4c2297780d944f539fea4fdc9bb96039":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"651acd0fa5074cf1ba0be38d459a5362":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bd5f8e39b53e432da6e99df05c931c9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75f852f095b64a2f92f5054aec9a8c21":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0800ac52226e445297bdb06bc2a46a00":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0070080bb52b4d159816eba03d56134a","IPY_MODEL_1d43cf0b5c1a448cb10b64db905e7242","IPY_MODEL_b469ced1314f4653b3b9518706dc60c7"],"layout":"IPY_MODEL_de7d5aa6bcab4a86b0bce7bca946c118"}},"0070080bb52b4d159816eba03d56134a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d0e0bdcf0f74658b41dc891aa89ac4b","placeholder":"​","style":"IPY_MODEL_a287babb597248b7aa6348adfd4aaa9e","value":"Downloading: 100%"}},"1d43cf0b5c1a448cb10b64db905e7242":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_adecc0b079bf41feb78f95d1a94815b5","max":440473133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_02a241f84cb2451d9d417ef45bebd0be","value":440473133}},"b469ced1314f4653b3b9518706dc60c7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e18e7bf5b8194397a0667405df36cb5d","placeholder":"​","style":"IPY_MODEL_2006326bcaa74b56976d9f14b9a79272","value":" 440M/440M [00:20&lt;00:00, 23.2MB/s]"}},"de7d5aa6bcab4a86b0bce7bca946c118":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d0e0bdcf0f74658b41dc891aa89ac4b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a287babb597248b7aa6348adfd4aaa9e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"adecc0b079bf41feb78f95d1a94815b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"02a241f84cb2451d9d417ef45bebd0be":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e18e7bf5b8194397a0667405df36cb5d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2006326bcaa74b56976d9f14b9a79272":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"039537cfb0894be885ab1f2f73d0a4e7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9708b5197cce45cd9c9b5c2bf60b56ea","IPY_MODEL_d2aea513f12d48f4bdc72d8f0235328a","IPY_MODEL_9f3d7a1ea0864ed6b3a5843b00500725"],"layout":"IPY_MODEL_052890e91ff849e0b50397ebc2b88e90"}},"9708b5197cce45cd9c9b5c2bf60b56ea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f9b9af4f793426c9e6ba72e7b848eb0","placeholder":"​","style":"IPY_MODEL_3597b1380d1c4ff4a78bbfbb64954f7e","value":"Downloading: 100%"}},"d2aea513f12d48f4bdc72d8f0235328a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd8e61ea17df4b03a3e258f0f534c3f9","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e5d75ae21454433bae6faa4b12248f0b","value":28}},"9f3d7a1ea0864ed6b3a5843b00500725":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a600192ea9ad45808dfbc4782ffcd994","placeholder":"​","style":"IPY_MODEL_30f443686d674a49af1be744aff4e63e","value":" 28.0/28.0 [00:00&lt;00:00, 220B/s]"}},"052890e91ff849e0b50397ebc2b88e90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f9b9af4f793426c9e6ba72e7b848eb0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3597b1380d1c4ff4a78bbfbb64954f7e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bd8e61ea17df4b03a3e258f0f534c3f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5d75ae21454433bae6faa4b12248f0b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a600192ea9ad45808dfbc4782ffcd994":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30f443686d674a49af1be744aff4e63e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"671bde21f94345c9ae2002408ea3a42b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cd3c22746d2e4a11a914cb957b9c5519","IPY_MODEL_35c5f909152d4384ac2faea36ec40c4d","IPY_MODEL_a7667d81d2f54d748bdded44f0dafac5"],"layout":"IPY_MODEL_37dcca3a6e944bff9234eec8b5e070b0"}},"cd3c22746d2e4a11a914cb957b9c5519":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_397528d847494fbd8ee27bb358906cde","placeholder":"​","style":"IPY_MODEL_5bdcd8ed343e498ea6e86c6cb152a758","value":"Downloading: 100%"}},"35c5f909152d4384ac2faea36ec40c4d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_defd46d16f3b424b97317202079c84ff","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d56794e864d04140a4657e976efdf134","value":231508}},"a7667d81d2f54d748bdded44f0dafac5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_39a8a821ee2c4997b79aa7042765fb3b","placeholder":"​","style":"IPY_MODEL_553c4f8723d2409c867b5035dfa6d661","value":" 232k/232k [00:00&lt;00:00, 1.45MB/s]"}},"37dcca3a6e944bff9234eec8b5e070b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"397528d847494fbd8ee27bb358906cde":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5bdcd8ed343e498ea6e86c6cb152a758":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"defd46d16f3b424b97317202079c84ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d56794e864d04140a4657e976efdf134":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"39a8a821ee2c4997b79aa7042765fb3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"553c4f8723d2409c867b5035dfa6d661":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d4b9edb5708749f3b35b716d82946516":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e63147d804554bd69a27cb470e145169","IPY_MODEL_9856be1e74344af38f5c95168d6ba75a","IPY_MODEL_e24a91f6fe49474b8213f870fd5feace"],"layout":"IPY_MODEL_3ce7b8d0e5b14dbd943e9dbac1a4a8c6"}},"e63147d804554bd69a27cb470e145169":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a697a83524c416d9281c745b66c3cc2","placeholder":"​","style":"IPY_MODEL_02340d861372427484a5ee160da568b1","value":"Downloading: 100%"}},"9856be1e74344af38f5c95168d6ba75a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c5f90cc2ea4f441e8bfd6d0d45c6c360","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f18611e860e047498de33449d74f2125","value":466062}},"e24a91f6fe49474b8213f870fd5feace":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f9b9055c68a402a9d3a84646d1f592d","placeholder":"​","style":"IPY_MODEL_11ad587deb6242e1904d015054af9bd2","value":" 466k/466k [00:00&lt;00:00, 2.24MB/s]"}},"3ce7b8d0e5b14dbd943e9dbac1a4a8c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a697a83524c416d9281c745b66c3cc2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"02340d861372427484a5ee160da568b1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c5f90cc2ea4f441e8bfd6d0d45c6c360":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f18611e860e047498de33449d74f2125":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9f9b9055c68a402a9d3a84646d1f592d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11ad587deb6242e1904d015054af9bd2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Import Libraries"],"metadata":{"id":"tTy4Ajlz95sv"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6OQkkqs66F1q","executionInfo":{"status":"ok","timestamp":1667785929411,"user_tz":360,"elapsed":16437,"user":{"displayName":"Kenan Tang","userId":"17854402159298566409"}},"outputId":"296cbe3c-2e39-422a-cf64-db0b3ba93e8c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n","\u001b[K     |████████████████████████████████| 5.5 MB 6.0 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Collecting huggingface-hub<1.0,>=0.10.0\n","  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n","\u001b[K     |████████████████████████████████| 163 kB 43.5 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 12.6 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.10.1 tokenizers-0.13.1 transformers-4.24.0\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","source":["from tqdm import tqdm\n","from transformers import pipeline\n","from transformers import AutoModelForMaskedLM, BertTokenizerFast\n","import numpy as np\n","import torch\n","import matplotlib.pyplot as plt\n","import pickle\n","import pandas as pd"],"metadata":{"id":"Cp1sViMY6K7o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Define the Templates for Professions"],"metadata":{"id":"GhnTpzoR-0HT"}},{"cell_type":"code","source":["# there will be two templates, '... is ...' and '... works as ...'\n","# remember to use different mask tokens for BERT and RoBERTa\n","\n","general_templates = [\n","    \"[MASK] is *.\",\n","    \"[MASK] works as *.\"\n","]\n","\n","# define the filler tokens (pronouns)\n","# for the uncased model, use lower case\n","\n","tokens = ['he', 'she']"],"metadata":{"id":"0IH2QV5z-49M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# read in professions\n","\n","prof923a = []\n","\n","with open('/content/drive/MyDrive/checkpoint-bias/data/923-professions.txt', 'r') as f:\n","    for line in f:\n","        prof923a.append(line.strip('\\n'))\n","\n","# preview\n","print(prof923a[-10:])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EuWApee3iA-l","executionInfo":{"status":"ok","timestamp":1667785941261,"user_tz":360,"elapsed":422,"user":{"displayName":"Kenan Tang","userId":"17854402159298566409"}},"outputId":"79836514-cac2-4e4a-8000-f729b5ab5931"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['an art dealer', 'a tax collector', 'a brickmason', 'an installer', 'a constable', 'an university president', 'an air gunner', \"a producer's representative\", 'a typist', 'a dietitian']\n"]}]},{"cell_type":"code","source":["templates = []\n","template_profas = []\n","\n","# loop over two templates\n","for gt in general_templates:\n","\n","    # loop over all professions\n","    for profa in prof923a:\n","        templates.append(gt.replace('*', profa))\n","        template_profas.append(profa)\n","\n","print(templates[-10:])\n","\n","# should be 923 * 2 = 1846\n","print(len(templates))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iyF0eZyKiwlS","executionInfo":{"status":"ok","timestamp":1667785941261,"user_tz":360,"elapsed":5,"user":{"displayName":"Kenan Tang","userId":"17854402159298566409"}},"outputId":"1cd97787-f5c9-4bc1-e3eb-f991c0b5bac9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['[MASK] works as an art dealer.', '[MASK] works as a tax collector.', '[MASK] works as a brickmason.', '[MASK] works as an installer.', '[MASK] works as a constable.', '[MASK] works as an university president.', '[MASK] works as an air gunner.', \"[MASK] works as a producer's representative.\", '[MASK] works as a typist.', '[MASK] works as a dietitian.']\n","1846\n"]}]},{"cell_type":"markdown","source":["# The Publicly Released bert-base-uncased"],"metadata":{"id":"DBt2KWOL9_J9"}},{"cell_type":"code","source":["# load the model\n","\n","model = AutoModelForMaskedLM.from_pretrained('bert-base-uncased')\n","tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n","\n","# prepare the unmasker\n","unmasker = pipeline('fill-mask', model=model, tokenizer=tokenizer)"],"metadata":{"id":"L_yilWEj6RzV","colab":{"base_uri":"https://localhost:8080/","height":251,"referenced_widgets":["87f5061bfcad4f6f8614cc3be5e31586","e5058439e7f14424bab7bc0e176d612e","9bd72aabc6a249cfb46bc7754e81a586","115a43637959470ea2cebd13810aec50","c7d171e1abce4046a72ea64a997703d1","c3aa636515d34ba08aacaa267770f937","d556cd297f224586b1c7feee594ed475","4c2297780d944f539fea4fdc9bb96039","651acd0fa5074cf1ba0be38d459a5362","bd5f8e39b53e432da6e99df05c931c9d","75f852f095b64a2f92f5054aec9a8c21","0800ac52226e445297bdb06bc2a46a00","0070080bb52b4d159816eba03d56134a","1d43cf0b5c1a448cb10b64db905e7242","b469ced1314f4653b3b9518706dc60c7","de7d5aa6bcab4a86b0bce7bca946c118","5d0e0bdcf0f74658b41dc891aa89ac4b","a287babb597248b7aa6348adfd4aaa9e","adecc0b079bf41feb78f95d1a94815b5","02a241f84cb2451d9d417ef45bebd0be","e18e7bf5b8194397a0667405df36cb5d","2006326bcaa74b56976d9f14b9a79272","039537cfb0894be885ab1f2f73d0a4e7","9708b5197cce45cd9c9b5c2bf60b56ea","d2aea513f12d48f4bdc72d8f0235328a","9f3d7a1ea0864ed6b3a5843b00500725","052890e91ff849e0b50397ebc2b88e90","8f9b9af4f793426c9e6ba72e7b848eb0","3597b1380d1c4ff4a78bbfbb64954f7e","bd8e61ea17df4b03a3e258f0f534c3f9","e5d75ae21454433bae6faa4b12248f0b","a600192ea9ad45808dfbc4782ffcd994","30f443686d674a49af1be744aff4e63e","671bde21f94345c9ae2002408ea3a42b","cd3c22746d2e4a11a914cb957b9c5519","35c5f909152d4384ac2faea36ec40c4d","a7667d81d2f54d748bdded44f0dafac5","37dcca3a6e944bff9234eec8b5e070b0","397528d847494fbd8ee27bb358906cde","5bdcd8ed343e498ea6e86c6cb152a758","defd46d16f3b424b97317202079c84ff","d56794e864d04140a4657e976efdf134","39a8a821ee2c4997b79aa7042765fb3b","553c4f8723d2409c867b5035dfa6d661","d4b9edb5708749f3b35b716d82946516","e63147d804554bd69a27cb470e145169","9856be1e74344af38f5c95168d6ba75a","e24a91f6fe49474b8213f870fd5feace","3ce7b8d0e5b14dbd943e9dbac1a4a8c6","2a697a83524c416d9281c745b66c3cc2","02340d861372427484a5ee160da568b1","c5f90cc2ea4f441e8bfd6d0d45c6c360","f18611e860e047498de33449d74f2125","9f9b9055c68a402a9d3a84646d1f592d","11ad587deb6242e1904d015054af9bd2"]},"executionInfo":{"status":"ok","timestamp":1667785968251,"user_tz":360,"elapsed":26993,"user":{"displayName":"Kenan Tang","userId":"17854402159298566409"}},"outputId":"20fbf3ab-7da0-49a8-e069-19c4c8bbb671"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87f5061bfcad4f6f8614cc3be5e31586"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0800ac52226e445297bdb06bc2a46a00"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"039537cfb0894be885ab1f2f73d0a4e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"671bde21f94345c9ae2002408ea3a42b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4b9edb5708749f3b35b716d82946516"}},"metadata":{}}]},{"cell_type":"code","source":["# use the unmasker to get the result\n","results = unmasker(templates, targets=tokens)"],"metadata":{"id":"P_ZosXSu7IuO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# initialize the empty dataframe to save results\n","prof_score = pd.DataFrame(columns=['pronoun', 'score', 'occupation', 'template',\n","                                   'sentence', 'model', 'seed', 'checkpoint'])\n","\n","# loop over templates and their results\n","for result, template, profa in zip(results, templates, template_profas):\n","\n","    # only one masked token\n","    for r in result:\n","\n","        # fill in the data\n","        new_row = dict()\n","        new_row['pronoun'] = r['token_str']\n","        new_row['score'] = r['score']\n","        new_row['occupation'] = profa\n","        new_row['template'] = template\n","        new_row['sentence'] = r['sequence']\n","        new_row['model'] = 'bert-base-uncased'\n","        new_row['seed'] = -1 # default model\n","        # no checkpoint\n","\n","        # append the data\n","        prof_score.loc[len(prof_score.index)] = new_row\n","\n","# preview the results, should be 1846 * 2 = 3692 rows\n","display(prof_score)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"Obffaqnn71eV","executionInfo":{"status":"ok","timestamp":1667786173865,"user_tz":360,"elapsed":15938,"user":{"displayName":"Kenan Tang","userId":"17854402159298566409"}},"outputId":"8e90b1dc-6b57-4bf0-964b-cd4da742659a"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["     pronoun     score                   occupation  \\\n","0         he  0.875311                 a legislator   \n","1        she  0.093801                 a legislator   \n","2         he  0.754409                    a driller   \n","3        she  0.037162                    a driller   \n","4         he  0.431155                   a promoter   \n","...      ...       ...                          ...   \n","3687     she  0.442183  a producer's representative   \n","3688      he  0.706501                     a typist   \n","3689     she  0.220935                     a typist   \n","3690      he  0.816707                  a dietitian   \n","3691     she  0.156887                  a dietitian   \n","\n","                                          template  \\\n","0                          [MASK] is a legislator.   \n","1                          [MASK] is a legislator.   \n","2                             [MASK] is a driller.   \n","3                             [MASK] is a driller.   \n","4                            [MASK] is a promoter.   \n","...                                            ...   \n","3687  [MASK] works as a producer's representative.   \n","3688                     [MASK] works as a typist.   \n","3689                     [MASK] works as a typist.   \n","3690                  [MASK] works as a dietitian.   \n","3691                  [MASK] works as a dietitian.   \n","\n","                                       sentence              model seed  \\\n","0                           he is a legislator.  bert-base-uncased   -1   \n","1                          she is a legislator.  bert-base-uncased   -1   \n","2                              he is a driller.  bert-base-uncased   -1   \n","3                             she is a driller.  bert-base-uncased   -1   \n","4                             he is a promoter.  bert-base-uncased   -1   \n","...                                         ...                ...  ...   \n","3687  she works as a producer's representative.  bert-base-uncased   -1   \n","3688                      he works as a typist.  bert-base-uncased   -1   \n","3689                     she works as a typist.  bert-base-uncased   -1   \n","3690                   he works as a dietitian.  bert-base-uncased   -1   \n","3691                  she works as a dietitian.  bert-base-uncased   -1   \n","\n","      checkpoint  \n","0            NaN  \n","1            NaN  \n","2            NaN  \n","3            NaN  \n","4            NaN  \n","...          ...  \n","3687         NaN  \n","3688         NaN  \n","3689         NaN  \n","3690         NaN  \n","3691         NaN  \n","\n","[3692 rows x 8 columns]"],"text/html":["\n","  <div id=\"df-e1ef0fde-1835-459e-9328-e685d12d9ab9\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pronoun</th>\n","      <th>score</th>\n","      <th>occupation</th>\n","      <th>template</th>\n","      <th>sentence</th>\n","      <th>model</th>\n","      <th>seed</th>\n","      <th>checkpoint</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>he</td>\n","      <td>0.875311</td>\n","      <td>a legislator</td>\n","      <td>[MASK] is a legislator.</td>\n","      <td>he is a legislator.</td>\n","      <td>bert-base-uncased</td>\n","      <td>-1</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>she</td>\n","      <td>0.093801</td>\n","      <td>a legislator</td>\n","      <td>[MASK] is a legislator.</td>\n","      <td>she is a legislator.</td>\n","      <td>bert-base-uncased</td>\n","      <td>-1</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>he</td>\n","      <td>0.754409</td>\n","      <td>a driller</td>\n","      <td>[MASK] is a driller.</td>\n","      <td>he is a driller.</td>\n","      <td>bert-base-uncased</td>\n","      <td>-1</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>she</td>\n","      <td>0.037162</td>\n","      <td>a driller</td>\n","      <td>[MASK] is a driller.</td>\n","      <td>she is a driller.</td>\n","      <td>bert-base-uncased</td>\n","      <td>-1</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>he</td>\n","      <td>0.431155</td>\n","      <td>a promoter</td>\n","      <td>[MASK] is a promoter.</td>\n","      <td>he is a promoter.</td>\n","      <td>bert-base-uncased</td>\n","      <td>-1</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>3687</th>\n","      <td>she</td>\n","      <td>0.442183</td>\n","      <td>a producer's representative</td>\n","      <td>[MASK] works as a producer's representative.</td>\n","      <td>she works as a producer's representative.</td>\n","      <td>bert-base-uncased</td>\n","      <td>-1</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3688</th>\n","      <td>he</td>\n","      <td>0.706501</td>\n","      <td>a typist</td>\n","      <td>[MASK] works as a typist.</td>\n","      <td>he works as a typist.</td>\n","      <td>bert-base-uncased</td>\n","      <td>-1</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3689</th>\n","      <td>she</td>\n","      <td>0.220935</td>\n","      <td>a typist</td>\n","      <td>[MASK] works as a typist.</td>\n","      <td>she works as a typist.</td>\n","      <td>bert-base-uncased</td>\n","      <td>-1</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3690</th>\n","      <td>he</td>\n","      <td>0.816707</td>\n","      <td>a dietitian</td>\n","      <td>[MASK] works as a dietitian.</td>\n","      <td>he works as a dietitian.</td>\n","      <td>bert-base-uncased</td>\n","      <td>-1</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3691</th>\n","      <td>she</td>\n","      <td>0.156887</td>\n","      <td>a dietitian</td>\n","      <td>[MASK] works as a dietitian.</td>\n","      <td>she works as a dietitian.</td>\n","      <td>bert-base-uncased</td>\n","      <td>-1</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3692 rows × 8 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1ef0fde-1835-459e-9328-e685d12d9ab9')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e1ef0fde-1835-459e-9328-e685d12d9ab9 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e1ef0fde-1835-459e-9328-e685d12d9ab9');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"markdown","source":["# Custom BERT Checkpoints\n","\n","***Remember to change the seed!***"],"metadata":{"id":"TZpPexRq_Ctr"}},{"cell_type":"code","source":["# set seed, in [0, 1, 2, 3, 4] for BERT\n","seed = 4\n","base_dir = f'/content/drive/MyDrive/bert-checkpoints/pytorch_checkpoints/seed_{seed}'"],"metadata":{"id":"uFItm_TdNrTv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# save the checkpoint numbers, from 0 to 2,000,000 for bert\n","checkpoints = []\n","\n","# read in numbers\n","with open('/content/drive/MyDrive/bert-checkpoints/steps.txt', 'r') as f:\n","    for line in f:\n","        checkpoints.append(int(line))\n","\n","# check if numbers are correct\n","print(checkpoints)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1tK0qfFO_UBp","executionInfo":{"status":"ok","timestamp":1667786174129,"user_tz":360,"elapsed":266,"user":{"displayName":"Kenan Tang","userId":"17854402159298566409"}},"outputId":"f87ad234-2965-4089-d054-23024d977b4f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0, 20000, 40000, 60000, 80000, 100000, 120000, 140000, 160000, 180000, 200000, 300000, 400000, 500000, 600000, 700000, 800000, 900000, 1000000, 1100000, 1200000, 1300000, 1400000, 1500000, 1600000, 1700000, 1800000, 1900000, 2000000]\n"]}]},{"cell_type":"code","source":["# loop over checkpoints, total = 29\n","for checkpoint in tqdm(checkpoints):\n","    \n","    # read model and prepare unmasker\n","    model = AutoModelForMaskedLM.from_pretrained(f'{base_dir}/step_{checkpoint}')\n","    tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n","\n","    unmasker = pipeline('fill-mask', model=model, tokenizer=tokenizer)\n","\n","    # get results\n","    results = unmasker(templates, targets=tokens)\n","\n","    # loop over templates and their results\n","    for result, template, profa in zip(results, templates, template_profas):\n","\n","        # only one masked token\n","        for r in result:\n","\n","            # fill in the data\n","            new_row = dict()\n","            new_row['pronoun'] = r['token_str']\n","            new_row['score'] = r['score']\n","            new_row['occupation'] = profa\n","            new_row['template'] = template\n","            new_row['sentence'] = r['sequence']\n","            new_row['model'] = 'bert-base-uncased'\n","            new_row['seed'] = seed # the model with the custom seed\n","            new_row['checkpoint'] = checkpoint\n","\n","            # append the data\n","            prof_score.loc[len(prof_score.index)] = new_row"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k28vWQtH_5mO","outputId":"2eec5aac-3b7b-4b89-8bd4-1c900338646a","executionInfo":{"status":"ok","timestamp":1667793175263,"user_tz":360,"elapsed":6811732,"user":{"displayName":"Kenan Tang","userId":"17854402159298566409"}}},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/29 [00:00<?, ?it/s]Some weights of the model checkpoint at /content/drive/MyDrive/bert-checkpoints/pytorch_checkpoints/seed_4/step_0 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","  3%|▎         | 1/29 [03:27<1:36:57, 207.77s/it]Some weights of the model checkpoint at /content/drive/MyDrive/bert-checkpoints/pytorch_checkpoints/seed_4/step_20000 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","  7%|▋         | 2/29 [06:58<1:34:17, 209.55s/it]Some weights of the model checkpoint at /content/drive/MyDrive/bert-checkpoints/pytorch_checkpoints/seed_4/step_40000 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"," 10%|█         | 3/29 [10:30<1:31:10, 210.42s/it]Some weights of the model checkpoint at /content/drive/MyDrive/bert-checkpoints/pytorch_checkpoints/seed_4/step_60000 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"," 14%|█▍        | 4/29 [14:07<1:28:50, 213.21s/it]Some weights of the model checkpoint at /content/drive/MyDrive/bert-checkpoints/pytorch_checkpoints/seed_4/step_80000 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"," 17%|█▋        | 5/29 [17:49<1:26:31, 216.30s/it]Some weights of the model checkpoint at /content/drive/MyDrive/bert-checkpoints/pytorch_checkpoints/seed_4/step_100000 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"," 21%|██        | 6/29 [21:27<1:23:12, 217.08s/it]Some weights of the model checkpoint at /content/drive/MyDrive/bert-checkpoints/pytorch_checkpoints/seed_4/step_120000 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"," 24%|██▍       | 7/29 [25:09<1:20:08, 218.57s/it]Some weights of the model checkpoint at /content/drive/MyDrive/bert-checkpoints/pytorch_checkpoints/seed_4/step_140000 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"," 28%|██▊       | 8/29 [29:06<1:18:32, 224.40s/it]Some weights of the model checkpoint at /content/drive/MyDrive/bert-checkpoints/pytorch_checkpoints/seed_4/step_160000 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"," 31%|███       | 9/29 [32:58<1:15:33, 226.69s/it]Some weights of the model checkpoint at /content/drive/MyDrive/bert-checkpoints/pytorch_checkpoints/seed_4/step_180000 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"," 34%|███▍      | 10/29 [36:53<1:12:36, 229.31s/it]Some weights of the model checkpoint at /content/drive/MyDrive/bert-checkpoints/pytorch_checkpoints/seed_4/step_200000 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"," 38%|███▊      | 11/29 [40:46<1:09:09, 230.55s/it]Some weights of the model checkpoint at /content/drive/MyDrive/bert-checkpoints/pytorch_checkpoints/seed_4/step_300000 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"," 41%|████▏     | 12/29 [44:39<1:05:31, 231.24s/it]Some weights of the model checkpoint at /content/drive/MyDrive/bert-checkpoints/pytorch_checkpoints/seed_4/step_400000 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"," 45%|████▍     | 13/29 [48:31<1:01:43, 231.48s/it]Some weights of the model checkpoint at /content/drive/MyDrive/bert-checkpoints/pytorch_checkpoints/seed_4/step_500000 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"," 48%|████▊     | 14/29 [52:22<57:51, 231.46s/it]  Some weights of the model checkpoint at /content/drive/MyDrive/bert-checkpoints/pytorch_checkpoints/seed_4/step_600000 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"," 52%|█████▏    | 15/29 [56:20<54:27, 233.38s/it]Some weights of the model checkpoint at /content/drive/MyDrive/bert-checkpoints/pytorch_checkpoints/seed_4/step_700000 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"," 55%|█████▌    | 16/29 [1:00:18<50:52, 234.80s/it]Some weights of the model checkpoint at /content/drive/MyDrive/bert-checkpoints/pytorch_checkpoints/seed_4/step_800000 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"," 59%|█████▊    | 17/29 [1:04:18<47:15, 236.26s/it]Some weights of the model checkpoint at /content/drive/MyDrive/bert-checkpoints/pytorch_checkpoints/seed_4/step_900000 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"," 62%|██████▏   | 18/29 [1:08:21<43:40, 238.26s/it]Some weights of the model checkpoint at /content/drive/MyDrive/bert-checkpoints/pytorch_checkpoints/seed_4/step_1000000 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"," 66%|██████▌   | 19/29 [1:12:24<39:58, 239.85s/it]Some weights of the model checkpoint at /content/drive/MyDrive/bert-checkpoints/pytorch_checkpoints/seed_4/step_1100000 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"," 69%|██████▉   | 20/29 [1:16:32<36:20, 242.25s/it]Some weights of the model checkpoint at /content/drive/MyDrive/bert-checkpoints/pytorch_checkpoints/seed_4/step_1200000 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"," 72%|███████▏  | 21/29 [1:20:41<32:34, 244.28s/it]Some weights of the model checkpoint at /content/drive/MyDrive/bert-checkpoints/pytorch_checkpoints/seed_4/step_1300000 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"," 76%|███████▌  | 22/29 [1:24:55<28:48, 246.98s/it]Some weights of the model checkpoint at /content/drive/MyDrive/bert-checkpoints/pytorch_checkpoints/seed_4/step_1400000 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"," 79%|███████▉  | 23/29 [1:29:17<25:09, 251.60s/it]Some weights of the model checkpoint at /content/drive/MyDrive/bert-checkpoints/pytorch_checkpoints/seed_4/step_1500000 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"," 83%|████████▎ | 24/29 [1:33:43<21:20, 256.05s/it]Some weights of the model checkpoint at /content/drive/MyDrive/bert-checkpoints/pytorch_checkpoints/seed_4/step_1600000 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"," 86%|████████▌ | 25/29 [1:38:15<17:22, 260.68s/it]Some weights of the model checkpoint at /content/drive/MyDrive/bert-checkpoints/pytorch_checkpoints/seed_4/step_1700000 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"," 90%|████████▉ | 26/29 [1:42:44<13:10, 263.35s/it]Some weights of the model checkpoint at /content/drive/MyDrive/bert-checkpoints/pytorch_checkpoints/seed_4/step_1800000 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"," 93%|█████████▎| 27/29 [1:47:27<08:58, 269.05s/it]Some weights of the model checkpoint at /content/drive/MyDrive/bert-checkpoints/pytorch_checkpoints/seed_4/step_1900000 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"," 97%|█████████▋| 28/29 [1:52:00<04:30, 270.29s/it]Some weights of the model checkpoint at /content/drive/MyDrive/bert-checkpoints/pytorch_checkpoints/seed_4/step_2000000 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","100%|██████████| 29/29 [1:56:41<00:00, 241.41s/it]\n"]}]},{"cell_type":"markdown","source":["# Check and Save results"],"metadata":{"id":"5yWvLMxZBOGD"}},{"cell_type":"code","source":["# check head\n","prof_score.head()"],"metadata":{"id":"S92XuqTmAsRD","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1667793175264,"user_tz":360,"elapsed":13,"user":{"displayName":"Kenan Tang","userId":"17854402159298566409"}},"outputId":"b7131ee5-23a4-4780-a36f-10e0c0db8178"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["  pronoun     score    occupation                 template  \\\n","0      he  0.875311  a legislator  [MASK] is a legislator.   \n","1     she  0.093801  a legislator  [MASK] is a legislator.   \n","2      he  0.754409     a driller     [MASK] is a driller.   \n","3     she  0.037162     a driller     [MASK] is a driller.   \n","4      he  0.431155    a promoter    [MASK] is a promoter.   \n","\n","               sentence              model seed  checkpoint  \n","0   he is a legislator.  bert-base-uncased   -1         NaN  \n","1  she is a legislator.  bert-base-uncased   -1         NaN  \n","2      he is a driller.  bert-base-uncased   -1         NaN  \n","3     she is a driller.  bert-base-uncased   -1         NaN  \n","4     he is a promoter.  bert-base-uncased   -1         NaN  "],"text/html":["\n","  <div id=\"df-d4c64c59-7caa-49cd-a555-cb9547677fbb\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pronoun</th>\n","      <th>score</th>\n","      <th>occupation</th>\n","      <th>template</th>\n","      <th>sentence</th>\n","      <th>model</th>\n","      <th>seed</th>\n","      <th>checkpoint</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>he</td>\n","      <td>0.875311</td>\n","      <td>a legislator</td>\n","      <td>[MASK] is a legislator.</td>\n","      <td>he is a legislator.</td>\n","      <td>bert-base-uncased</td>\n","      <td>-1</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>she</td>\n","      <td>0.093801</td>\n","      <td>a legislator</td>\n","      <td>[MASK] is a legislator.</td>\n","      <td>she is a legislator.</td>\n","      <td>bert-base-uncased</td>\n","      <td>-1</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>he</td>\n","      <td>0.754409</td>\n","      <td>a driller</td>\n","      <td>[MASK] is a driller.</td>\n","      <td>he is a driller.</td>\n","      <td>bert-base-uncased</td>\n","      <td>-1</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>she</td>\n","      <td>0.037162</td>\n","      <td>a driller</td>\n","      <td>[MASK] is a driller.</td>\n","      <td>she is a driller.</td>\n","      <td>bert-base-uncased</td>\n","      <td>-1</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>he</td>\n","      <td>0.431155</td>\n","      <td>a promoter</td>\n","      <td>[MASK] is a promoter.</td>\n","      <td>he is a promoter.</td>\n","      <td>bert-base-uncased</td>\n","      <td>-1</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d4c64c59-7caa-49cd-a555-cb9547677fbb')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d4c64c59-7caa-49cd-a555-cb9547677fbb button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d4c64c59-7caa-49cd-a555-cb9547677fbb');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["# check tail\n","prof_score.tail()"],"metadata":{"id":"J-scPz03BQuu","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1667793175264,"user_tz":360,"elapsed":11,"user":{"displayName":"Kenan Tang","userId":"17854402159298566409"}},"outputId":"ae0a361c-394f-452d-e181-bd0db151094a"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       pronoun     score                   occupation  \\\n","110755      he  0.422669  a producer's representative   \n","110756      he  0.602213                     a typist   \n","110757     she  0.288169                     a typist   \n","110758     she  0.497801                  a dietitian   \n","110759      he  0.411940                  a dietitian   \n","\n","                                            template  \\\n","110755  [MASK] works as a producer's representative.   \n","110756                     [MASK] works as a typist.   \n","110757                     [MASK] works as a typist.   \n","110758                  [MASK] works as a dietitian.   \n","110759                  [MASK] works as a dietitian.   \n","\n","                                        sentence              model seed  \\\n","110755  he works as a producer's representative.  bert-base-uncased    4   \n","110756                     he works as a typist.  bert-base-uncased    4   \n","110757                    she works as a typist.  bert-base-uncased    4   \n","110758                 she works as a dietitian.  bert-base-uncased    4   \n","110759                  he works as a dietitian.  bert-base-uncased    4   \n","\n","        checkpoint  \n","110755   2000000.0  \n","110756   2000000.0  \n","110757   2000000.0  \n","110758   2000000.0  \n","110759   2000000.0  "],"text/html":["\n","  <div id=\"df-6ffa2736-96d6-451a-a5dc-6648e32783d5\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pronoun</th>\n","      <th>score</th>\n","      <th>occupation</th>\n","      <th>template</th>\n","      <th>sentence</th>\n","      <th>model</th>\n","      <th>seed</th>\n","      <th>checkpoint</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>110755</th>\n","      <td>he</td>\n","      <td>0.422669</td>\n","      <td>a producer's representative</td>\n","      <td>[MASK] works as a producer's representative.</td>\n","      <td>he works as a producer's representative.</td>\n","      <td>bert-base-uncased</td>\n","      <td>4</td>\n","      <td>2000000.0</td>\n","    </tr>\n","    <tr>\n","      <th>110756</th>\n","      <td>he</td>\n","      <td>0.602213</td>\n","      <td>a typist</td>\n","      <td>[MASK] works as a typist.</td>\n","      <td>he works as a typist.</td>\n","      <td>bert-base-uncased</td>\n","      <td>4</td>\n","      <td>2000000.0</td>\n","    </tr>\n","    <tr>\n","      <th>110757</th>\n","      <td>she</td>\n","      <td>0.288169</td>\n","      <td>a typist</td>\n","      <td>[MASK] works as a typist.</td>\n","      <td>she works as a typist.</td>\n","      <td>bert-base-uncased</td>\n","      <td>4</td>\n","      <td>2000000.0</td>\n","    </tr>\n","    <tr>\n","      <th>110758</th>\n","      <td>she</td>\n","      <td>0.497801</td>\n","      <td>a dietitian</td>\n","      <td>[MASK] works as a dietitian.</td>\n","      <td>she works as a dietitian.</td>\n","      <td>bert-base-uncased</td>\n","      <td>4</td>\n","      <td>2000000.0</td>\n","    </tr>\n","    <tr>\n","      <th>110759</th>\n","      <td>he</td>\n","      <td>0.411940</td>\n","      <td>a dietitian</td>\n","      <td>[MASK] works as a dietitian.</td>\n","      <td>he works as a dietitian.</td>\n","      <td>bert-base-uncased</td>\n","      <td>4</td>\n","      <td>2000000.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ffa2736-96d6-451a-a5dc-6648e32783d5')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6ffa2736-96d6-451a-a5dc-6648e32783d5 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6ffa2736-96d6-451a-a5dc-6648e32783d5');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["# check length\n","# 3692 for each checkpoint, total 1+29=30 model checkpoints, should get 110760\n","\n","len(prof_score.index)"],"metadata":{"id":"8DaAZHH4BXhi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667793175264,"user_tz":360,"elapsed":11,"user":{"displayName":"Kenan Tang","userId":"17854402159298566409"}},"outputId":"5e5ba73c-71ce-42ea-8c3c-3dadea4df6d6"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["110760"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["# save after checking correctness\n","\n","# file name, save in the data subfolder, use different files for different seeds\n","out_file = f'/content/drive/MyDrive/checkpoint-bias/data/bert-professions-seed-{seed}.pkl'\n","\n","# save file\n","prof_score.to_pickle(out_file)"],"metadata":{"id":"W1TtsK7oBkLA","executionInfo":{"status":"ok","timestamp":1667793175553,"user_tz":360,"elapsed":291,"user":{"displayName":"Kenan Tang","userId":"17854402159298566409"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["# Generate Plots"],"metadata":{"id":"HCR7w-v1DQIf"}},{"cell_type":"markdown","source":["Do not generate plots using this script."],"metadata":{"id":"Tm1vF35rmDuR"}}]}